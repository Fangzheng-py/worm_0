{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BsYMk8pYiLRC",
    "outputId": "5fc4827b-cf89-4ab2-f369-8fd30006936f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('device', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "uMbiyPiTj1Q-"
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "test_transform = transforms.Compose([transforms.Resize((224, 224)),\n",
    "                                     transforms.Grayscale(1),\n",
    "                                     #transforms.CenterCrop(224),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     #transforms.Normalize([0.485, ], [0.229, ])\n",
    "                                     ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "6NFglAzHj7cG"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/liFangzheng/Desktop/2normal_development_timeline/umap/umap_data/umap_profile.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "eH9JziknkGk0"
   },
   "outputs": [],
   "source": [
    "model = torch.load('C:/Users/liFangzheng/Desktop/2normal_development_timeline/save/best-0.940.pth')\n",
    "model = model.eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "dyskDUNJkP3v"
   },
   "outputs": [],
   "source": [
    "from torchvision.models.feature_extraction import create_feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "IUb1r7y9kTMo"
   },
   "outputs": [],
   "source": [
    "model_trunc = create_feature_extractor(model, return_nodes={'avgpool': 'semantic_feature'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3HcoVBujkVAE",
    "outputId": "022db1ba-8768-41b0-fe71-dc9cf901194f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 695/695 [00:06<00:00, 115.31it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "encoding_array = []\n",
    "img_path_list = []\n",
    "\n",
    "for img_path in tqdm(df['path']):\n",
    "    img_path_list.append(img_path)\n",
    "    img_pil = Image.open(img_path)\n",
    "    input_img = test_transform(img_pil).unsqueeze(0).to(device) \n",
    "    feature = model_trunc(input_img)['semantic_feature'].squeeze().detach().cpu().numpy() \n",
    "    encoding_array.append(feature)\n",
    "encoding_array = np.array(encoding_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gZ7Yh4PGkZHW",
    "outputId": "eb77e7a6-abbd-4cdb-8b47-9d9a5acc654e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(695, 512)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "721wNiYxxg8m",
    "outputId": "df2f10ba-ae6e-4a3f-8fea-3487d559a138"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49333626, 0.41650647, 0.2647683 , ..., 0.38125345, 0.05651681,\n",
       "        0.711309  ],\n",
       "       [0.1789156 , 0.33345312, 0.18967134, ..., 0.8800947 , 0.6996626 ,\n",
       "        0.86289835],\n",
       "       [0.62160426, 0.5914295 , 0.7573102 , ..., 0.37744802, 0.19713576,\n",
       "        0.95394725],\n",
       "       ...,\n",
       "       [0.2847594 , 0.3567578 , 0.7257049 , ..., 0.7140565 , 0.73424035,\n",
       "        0.37235504],\n",
       "       [0.56962633, 0.72640496, 0.4826683 , ..., 0.0683881 , 0.39096987,\n",
       "        0.10597584],\n",
       "       [0.30710456, 0.6038988 , 0.43015373, ..., 0.03866735, 0.17592604,\n",
       "        0.08208882]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "0q2imnZyk3xI"
   },
   "outputs": [],
   "source": [
    "np.save('C:/Users/liFangzheng/Desktop/2normal_development_timeline/umap/umap_data/test_feature.npy', encoding_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fsNVGcxzlG64"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
