{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2d217b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader, dataloader, random_split\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "import pandas as pd\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0264002f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using torch 2.0.0 _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12287MB, multi_processor_count=28)\n"
     ]
    }
   ],
   "source": [
    "print('Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94198bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pth file path\n",
    "pth_file_path = 'C:/Users/liFangzheng/Desktop/completed_AI_program/ResU-Net/save/embryo_seg.pth'\n",
    "#images path\n",
    "img_path = 'C:/Users/liFangzheng/Desktop/LI_development/new/elt-1/input/'\n",
    "#save images path\n",
    "save_path = 'C:/Users/liFangzheng/Desktop/LI_development/new/elt-1/output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef4518d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do not modifyÔºÅ\n",
    "N_CLASSES       = 1\n",
    "LEARNING_RATE   = 0.002\n",
    "START_FRAME     = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48df5615",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchActivate(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(BatchActivate, self).__init__()\n",
    "        self.norm = nn.BatchNorm2d(num_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.relu(self.norm(x))\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel=3, padding=1, stride=1, activation=True):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
    "                            kernel_size=kernel, stride=stride, padding=padding)\n",
    "        self.batchnorm  = BatchActivate(out_channels)\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        if self.activation:\n",
    "            x = self.batchnorm(x)\n",
    "        return x\n",
    "\n",
    "class DoubleConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel=3, padding=1, stride=1):\n",
    "        super(DoubleConvBlock, self).__init__()\n",
    "        self.conv1 = ConvBlock(in_channels, out_channels, kernel, padding, stride)\n",
    "        self.conv2 = ConvBlock(out_channels, out_channels, kernel, padding, stride)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        return x\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, batch_activation=False):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.batch_activation = batch_activation\n",
    "        self.norm  = nn.BatchNorm2d(num_features=in_channels)\n",
    "        self.conv1 = ConvBlock(in_channels, in_channels, kernel=3, stride=1, padding=1)\n",
    "        self.conv2 = ConvBlock(in_channels, in_channels, kernel=3, stride=1, padding=1, activation=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.norm(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "\n",
    "        x += residual\n",
    "\n",
    "\n",
    "        if self.batch_activation:\n",
    "            x = self.norm(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2db2af72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet_ResNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, n_classes=N_CLASSES, dropout=0.1, start_fm=START_FRAME):\n",
    "        super(UNet_ResNet, self).__init__()\n",
    "\n",
    "        self.drop = dropout\n",
    "\n",
    "        self.pool = nn.MaxPool2d((2,2))\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, start_fm, 3, padding=(1,1)),\n",
    "            ResidualBlock(start_fm),\n",
    "            ResidualBlock(start_fm, batch_activation=True),\n",
    "\n",
    "        )\n",
    "\n",
    "        self.encoder_2 = nn.Sequential(\n",
    "            nn.Conv2d(start_fm, start_fm*2, 3, padding=(1,1)),\n",
    "            ResidualBlock(start_fm*2),\n",
    "            ResidualBlock(start_fm*2, batch_activation=True),\n",
    "\n",
    "        )\n",
    "\n",
    "        self.encoder_3 = nn.Sequential(\n",
    "            nn.Conv2d(start_fm*2, start_fm*4, 3, padding=(1,1)),\n",
    "            ResidualBlock(start_fm*4),\n",
    "            ResidualBlock(start_fm*4, batch_activation=True),\n",
    "\n",
    "        )\n",
    "\n",
    "        self.encoder_4 = nn.Sequential(\n",
    "            nn.Conv2d(start_fm*4, start_fm*8, 3, padding=(1,1)),\n",
    "            ResidualBlock(start_fm*8),\n",
    "            ResidualBlock(start_fm*8, batch_activation=True),\n",
    "\n",
    "        )\n",
    "\n",
    "        self.middle = nn.Sequential(\n",
    "            nn.Conv2d(start_fm*8, start_fm*16, 3, padding=3//2),\n",
    "            ResidualBlock(start_fm*16),\n",
    "            ResidualBlock(start_fm*16, batch_activation=True),\n",
    "\n",
    "        )\n",
    "\n",
    "\n",
    "        self.deconv_4  = nn.ConvTranspose2d(start_fm*16, start_fm*8, 2, 2)\n",
    "        self.deconv_3  = nn.ConvTranspose2d(start_fm*8, start_fm*4, 2, 2)\n",
    "        self.deconv_2  = nn.ConvTranspose2d(start_fm*4, start_fm*2, 2, 2)\n",
    "        self.deconv_1  = nn.ConvTranspose2d(start_fm*2, start_fm, 2, 2)\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder_4 = nn.Sequential(\n",
    "            nn.Dropout2d(dropout),\n",
    "            nn.Conv2d(start_fm*16, start_fm*8, 3, padding=(1,1)),\n",
    "            ResidualBlock(start_fm*8),\n",
    "            ResidualBlock(start_fm*8, batch_activation=True),\n",
    "        )\n",
    "\n",
    "        self.decoder_3 = nn.Sequential(\n",
    "            nn.Dropout2d(dropout),\n",
    "            nn.Conv2d(start_fm*8, start_fm*4, 3, padding=(1,1)),\n",
    "            ResidualBlock(start_fm*4),\n",
    "            ResidualBlock(start_fm*4, batch_activation=True),\n",
    "        )\n",
    "\n",
    "        self.decoder_2 = nn.Sequential(\n",
    "            nn.Dropout2d(dropout),\n",
    "            nn.Conv2d(start_fm*4, start_fm*2, 3, padding=(1,1)),\n",
    "            ResidualBlock(start_fm*2),\n",
    "            ResidualBlock(start_fm*2, batch_activation=True),\n",
    "        )\n",
    "\n",
    "        self.decoder_1 = nn.Sequential(\n",
    "            nn.Dropout2d(dropout),\n",
    "            nn.Conv2d(start_fm*2, start_fm, 3, padding=(1,1)),\n",
    "            ResidualBlock(start_fm),\n",
    "            ResidualBlock(start_fm, batch_activation=True),\n",
    "        )\n",
    "\n",
    "        self.conv_last = nn.Conv2d(start_fm, n_classes, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "\n",
    "        conv1 = self.encoder_1(x) #128\n",
    "        x = self.pool(conv1) # 64\n",
    "        x = nn.Dropout2d(self.drop)(x)\n",
    "\n",
    "        conv2 = self.encoder_2(x) #64\n",
    "        x = self.pool(conv2) # 32\n",
    "        x = nn.Dropout2d(self.drop)(x)\n",
    "\n",
    "        conv3 = self.encoder_3(x) #32\n",
    "        x = self.pool(conv3) #16\n",
    "        x = nn.Dropout2d(self.drop)(x)\n",
    "\n",
    "        conv4 = self.encoder_4(x) #16\n",
    "        x = self.pool(conv4) # 8\n",
    "        x = nn.Dropout2d(self.drop)(x)\n",
    "\n",
    "\n",
    "        # Middle\n",
    "        x     = self.middle(x) # 8\n",
    "\n",
    "        # Decoder\n",
    "        x     = self.deconv_4(x) #16\n",
    "        x     = torch.cat([conv4, x], dim=1) #16\n",
    "        x     = self.decoder_4(x)\n",
    "\n",
    "\n",
    "        x     = self.deconv_3(x) #32\n",
    "        x     = torch.cat([conv3, x], dim=1)\n",
    "        x     = self.decoder_3(x)\n",
    "\n",
    "\n",
    "        x     = self.deconv_2(x) #64\n",
    "        x     = torch.cat([conv2, x], dim=1)\n",
    "        x     = self.decoder_2(x)\n",
    "\n",
    "\n",
    "        x     = self.deconv_1(x) # 128\n",
    "        x     = torch.cat([conv1, x], dim=1)\n",
    "        x     = self.decoder_1(x)\n",
    "\n",
    "        out   = (self.conv_last(x)) # 128\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "758ac207",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor2np(tensor):\n",
    "    tensor = tensor.squeeze().cpu()\n",
    "    return tensor.detach().numpy()\n",
    "\n",
    "def normtensor(tensor):\n",
    "    tensor = torch.where(tensor<0., torch.zeros(1).cuda(), torch.ones(1).cuda())\n",
    "    return tensor\n",
    "\n",
    "def count_params(model):\n",
    "    pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "    return pytorch_total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "978f713f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(prev_model = None):\n",
    "    # Make the model\n",
    "    if prev_model == None:\n",
    "        model = UNet_ResNet().to(device)\n",
    "    else:\n",
    "        model = prev_model\n",
    "\n",
    "    print('Number of parameter:', count_params(model))\n",
    "\n",
    "    # Make the loss and optimizer\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer   = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    return model, criterion, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c550980",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eac18a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameter: 4896369\n"
     ]
    }
   ],
   "source": [
    "model, _, _ = make_model(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa778598",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    model.load_state_dict(torch.load(pth_file_path))\n",
    "except:\n",
    "    print('Can not load weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2599658",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model,input,device):\n",
    "    model.eval()\n",
    "    predicted_masks = []\n",
    "    with torch.no_grad():\n",
    "        predict = model(input)\n",
    "        predict = (predict > 0).type(torch.float)\n",
    "        predicted_masks.append(predict)\n",
    "    predicted_masks = torch.cat(predicted_masks)\n",
    "    return predicted_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45102db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval()\n",
    "model = model.to(device)\n",
    "test_transform = transforms.Compose([transforms.Grayscale(1),\n",
    "                                     transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a65e4de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name_path = glob.glob(os.path.join(img_path, \"*.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3860d9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.png\n",
      "150.png\n",
      "155.png\n",
      "160.png\n",
      "165.png\n",
      "170.png\n",
      "175.png\n",
      "180.png\n",
      "185.png\n",
      "190.png\n",
      "195.png\n",
      "200.png\n",
      "205.png\n",
      "210.png\n",
      "215.png\n",
      "220.png\n",
      "225.png\n",
      "230.png\n",
      "235.png\n",
      "240.png\n",
      "245.png\n",
      "250.png\n",
      "255.png\n",
      "260.png\n",
      "265.png\n",
      "270.png\n",
      "275.png\n",
      "280.png\n",
      "285.png\n",
      "290.png\n",
      "295.png\n",
      "300.png\n",
      "305.png\n",
      "310.png\n",
      "315.png\n",
      "320.png\n",
      "325.png\n",
      "330.png\n",
      "335.png\n",
      "340.png\n",
      "345.png\n",
      "350.png\n",
      "355.png\n",
      "360.png\n",
      "365.png\n",
      "370.png\n",
      "375.png\n",
      "380.png\n",
      "385.png\n",
      "390.png\n",
      "395.png\n",
      "400.png\n",
      "405.png\n",
      "410.png\n",
      "415.png\n",
      "420.png\n",
      "425.png\n",
      "430.png\n",
      "435.png\n",
      "440.png\n",
      "445.png\n",
      "450.png\n",
      "455.png\n",
      "460.png\n",
      "465.png\n",
      "470.png\n",
      "475.png\n",
      "480.png\n",
      "485.png\n",
      "490.png\n",
      "495.png\n",
      "500.png\n",
      "505.png\n",
      "510.png\n",
      "515.png\n",
      "520.png\n",
      "525.png\n",
      "530.png\n",
      "535.png\n",
      "540.png\n",
      "545.png\n",
      "550.png\n",
      "555.png\n",
      "560.png\n",
      "565.png\n",
      "570.png\n",
      "575.png\n"
     ]
    }
   ],
   "source": [
    "for file in image_name_path:\n",
    "    img_name = os.path.basename(file)\n",
    "    img_name = img_name.replace('.jpg','.png')\n",
    "    img_PIL = Image.open(file)\n",
    "    input_img = test_transform(img_PIL)\n",
    "    input_img_data = input_img.unsqueeze(0).to(device)\n",
    "    predicted_mask = predict(model, input_img_data, device=device)\n",
    "    org_image=input_img_data.to(device='cuda')\n",
    "    out_tensor = torch.mul(predicted_mask,org_image)\n",
    "    out_tensor = out_tensor.squeeze(dim=0)\n",
    "    enhance_image = transforms.ToPILImage()(out_tensor)\n",
    "    enhance_image.save(save_path+img_name,\"PNG\")\n",
    "    print(img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cc010d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4ed159",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
